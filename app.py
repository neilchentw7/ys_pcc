# -*- coding: utf-8 -*-
"""
app.py
Streamlit ä»‹é¢ï¼šå‘¼å« crawler.crawl_all() å–å¾—è³‡æ–™ä¸¦é¡¯ç¤º
"""
import streamlit as st
from crawler import crawl_all, AGENCIES

st.set_page_config(page_title="æ”¿åºœé›»å­æ¡è³¼ç¶²æ¨™æ¡ˆå¿«æŸ¥", layout="wide")
st.title("ğŸ“ æ”¿åºœé›»å­æ¡è³¼ç¶²ã€€å…«å¤§æ©Ÿé—œæœ€æ–°æ¨™æ¡ˆ")

st.write(
    f"æœ¬å·¥å…·å°‡ä¾åºçˆ¬å–ä»¥ä¸‹ **{len(AGENCIES)}** å€‹æ©Ÿé—œçš„ç¬¬ä¸€é æ¨™æ¡ˆï¼š\n\n"
    + "ã€".join(AGENCIES)
    + "\n\n"
    "å¾Œç«¯æ¡ç”¨ Selenium (headless Chrome)ï¼Œæ¯å€‹æ©Ÿé—œä¹‹é–“éš¨æ©Ÿä¼‘æ¯ 3â€“8 ç§’ï¼Œ"
    "ä»¥é™ä½è¢«å®˜æ–¹åçˆ¬æ©Ÿåˆ¶å°é–çš„é¢¨éšªã€‚"
)

if st.button("ğŸš€ é–‹å§‹æŠ“å–", type="primary"):
    with st.spinner("è³‡æ–™æ“·å–ä¸­ï¼Œè«‹ç¨å€™â€¦"):
        df = crawl_all()

    st.success(f"å®Œæˆï¼å…±å–å¾— {len(df)} ç­†è³‡æ–™ã€‚")
    st.dataframe(df, use_container_width=True)

    csv = df.to_csv(index=False, encoding="utf-8-sig")
    st.download_button("ğŸ’¾ ä¸‹è¼‰ CSV", csv, file_name="pcc_tenders.csv", mime="text/csv")
else:
    st.info("é»æ“Šä¸Šæ–¹æŒ‰éˆ•é–‹å§‹æŠ“å–ã€‚")
